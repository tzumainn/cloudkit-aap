---
gateway_settings:
  gateway_access_token_expiration: 7200

# Create a project from the specified git repo
controller_projects: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}"
    description: "{{ aap_project_name }}'s project"
    organization: "{{ aap_organization_name }}"
    scm_type: git
    scm_url: "{{ aap_project_git_uri }}"
    scm_branch: "{{ aap_project_git_branch }}"
    scm_clean: true
    scm_update_on_launch: true
    scm_credential: ""
    update_project: true
    wait: true

# Create cluster-fulfillment templates and a config-as-code template
controller_templates: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}-create-hosted-cluster"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_cloudkit_create_hosted_cluster.yml"
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-cluster-fulfillment-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-delete-hosted-cluster"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_cloudkit_delete_hosted_cluster.yml"
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-cluster-fulfillment-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-config-as-code"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_cloudkit_config_as_code.yml"
    inventory: "{{ aap_prefix }}-config-as-code"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-config-as-code-ig"
    verbosity: 0
  - name: "{{ aap_prefix }}-publish-templates"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "collections/ansible_collections/cloudkit/service/playbooks/publish_templates.yaml"
    inventory: "{{ aap_prefix }}-publish-templates"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-publish-templates-ig"
    verbosity: 0
  - name: "{{ aap_prefix }}-create-hosted-cluster-post-install"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_cloudkit_create_hosted_cluster_post_install.yml"
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-create-hosted-cluster-post-install-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-create-compute-instance"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_cloudkit_create_compute_instance.yml"
    inventory: "{{ aap_prefix }}-compute-instance-operations"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-compute-instance-operations-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-delete-compute-instance"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_cloudkit_delete_compute_instance.yml"
    inventory: "{{ aap_prefix }}-compute-instance-operations"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-compute-instance-operations-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-report-hosted-cluster-status-success"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_osac_report_hosted_cluster_status.yml"
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-cluster-fulfillment-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
    extra_vars:
      workflow_status: succeeded
  - name: "{{ aap_prefix }}-report-hosted-cluster-status-failure"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_osac_report_hosted_cluster_status.yml"
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-cluster-fulfillment-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
    extra_vars:
      workflow_status: failed
  - name: "{{ aap_prefix }}-create-hostpool"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_osac_create_hostpool.yml"
    inventory: "{{ aap_prefix }}-hostpool-operations"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-hostpool-operations-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-delete-hostpool"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_osac_delete_hostpool.yml"
    inventory: "{{ aap_prefix }}-hostpool-operations"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-hostpool-operations-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
  - name: "{{ aap_prefix }}-report-hostpool-status-success"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_osac_report_hostpool_status.yml"
    inventory: "{{ aap_prefix }}-hostpool-operations"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-hostpool-operations-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
    extra_vars:
      workflow_status: succeeded
  - name: "{{ aap_prefix }}-report-hostpool-status-failure"
    project: "{{ aap_prefix }}"
    organization: "{{ aap_organization_name }}"
    job_type: run
    playbook: "playbook_osac_report_hostpool_status.yml"
    inventory: "{{ aap_prefix }}-hostpool-operations"
    execution_environment: "{{ aap_prefix }}-ee"
    instance_groups:
      - "{{ aap_prefix }}-hostpool-operations-ig"
    allow_simultaneous: true
    ask_variables_on_launch: true
    verbosity: 0
    extra_vars:
      workflow_status: failed

controller_job_template_surveys: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}-create-hosted-cluster-post-install"
    survey_enabled: true
    survey_spec:
      name: "Create hosted cluster post-install survey"
      description: "Provide kubeconfig for post-install hosted cluster configuration"
      spec:
        - question_name: "admin_kubeconfig"
          question_description: "Kubeconfig file content for the hosted cluster"
          required: true
          type: "textarea"
          variable: "admin_kubeconfig"
          min: 0
          max: 65535
          default: ""
          new_question: true
          secret: true

# Create workflows for cluster and hostpool management
controller_workflows: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}-create-hosted-cluster-workflow"
    description: "Workflow for creating hosted cluster"
    organization: "{{ aap_organization_name }}"
    ask_variables_on_launch: true
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    allow_simultaneous: true
    extra_vars:
      workflow_name: create-hosted-cluster
    workflow_nodes:
      - identifier: "create-cluster"
        unified_job_template:
          name: "{{ aap_prefix }}-create-hosted-cluster"
          type: job_template
        related:
          success_nodes:
            - identifier: "post-install"
          failure_nodes:
            - identifier: "report-hosted-cluster-status-failure"
      - identifier: "post-install"
        unified_job_template:
          name: "{{ aap_prefix }}-create-hosted-cluster-post-install"
          type: job_template
        related:
          success_nodes:
            - identifier: "report-hosted-cluster-status-success"
          failure_nodes:
            - identifier: "report-hosted-cluster-status-failure"
      - identifier: "report-hosted-cluster-status-success"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hosted-cluster-status-success"
          type: job_template
      - identifier: "report-hosted-cluster-status-failure"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hosted-cluster-status-failure"
          type: job_template
  - name: "{{ aap_prefix }}-delete-hosted-cluster-workflow"
    description: "Workflow for deleting hosted cluster"
    organization: "{{ aap_organization_name }}"
    ask_variables_on_launch: true
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    allow_simultaneous: true
    extra_vars:
      workflow_name: delete-hosted-cluster
    workflow_nodes:
      - identifier: "delete-cluster"
        unified_job_template:
          name: "{{ aap_prefix }}-delete-hosted-cluster"
          type: job_template
        related:
          failure_nodes:
            - identifier: "report-hosted-cluster-status-failure"
          success_nodes:
            - identifier: "report-hosted-cluster-status-success"
      - identifier: "report-hosted-cluster-status-success"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hosted-cluster-status-success"
          type: job_template
      - identifier: "report-hosted-cluster-status-failure"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hosted-cluster-status-failure"
          type: job_template
  - name: "{{ aap_prefix }}-create-hostpool-workflow"
    description: "Workflow for creating hostpool"
    organization: "{{ aap_organization_name }}"
    ask_variables_on_launch: true
    inventory: "{{ aap_prefix }}-hostpool-operations"
    allow_simultaneous: true
    extra_vars:
      workflow_name: create-hostpool
    workflow_nodes:
      - identifier: "create"
        unified_job_template:
          name: "{{ aap_prefix }}-create-hostpool"
          type: job_template
        related:
          success_nodes:
            - identifier: "report-hostpool-status-success"
          failure_nodes:
            - identifier: "report-hostpool-status-failure"
      - identifier: "report-hostpool-status-success"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hostpool-status-success"
          type: job_template
      - identifier: "report-hostpool-status-failure"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hostpool-status-failure"
          type: job_template
  - name: "{{ aap_prefix }}-delete-hostpool-workflow"
    description: "Workflow for deleting hostpool"
    organization: "{{ aap_organization_name }}"
    ask_variables_on_launch: true
    inventory: "{{ aap_prefix }}-hostpool-operations"
    allow_simultaneous: true
    extra_vars:
      workflow_name: delete-hostpool
    workflow_nodes:
      - identifier: "delete"
        unified_job_template:
          name: "{{ aap_prefix }}-delete-hostpool"
          type: job_template
        related:
          failure_nodes:
            - identifier: "report-hostpool-status-failure"
          success_nodes:
            - identifier: "report-hostpool-status-success"
      - identifier: "report-hostpool-status-success"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hostpool-status-success"
          type: job_template
      - identifier: "report-hostpool-status-failure"
        unified_job_template:
          name: "{{ aap_prefix }}-report-hostpool-status-failure"
          type: job_template

# Create cluster fulfillment and confg-as-code inventories. They are the same
# for the moment, but spliting them will allow us to diverge easily in the
# future.
controller_inventories: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}-cluster-fulfillment"
    description: "Cluster fulfilment inventory"
    organization: "{{ aap_organization_name }}"
  - name: "{{ aap_prefix }}-config-as-code"
    description: "Config-as-code inventory"
    organization: "{{ aap_organization_name }}"
  - name: "{{ aap_prefix }}-publish-templates"
    description: "Publish templates inventory"
    organization: "{{ aap_organization_name }}"
  - name: "{{ aap_prefix }}-compute-instance-operations"
    description: "Compute Instance Operational Inventory"
    organization: "{{ aap_organization_name }}"
  - name: "{{ aap_prefix }}-hostpool-operations"
    description: "Host Pool Operational Inventory"
    organization: "{{ aap_organization_name }}"

controller_inventory_sources: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}-cluster-fulfillment-is"
    organization: "{{ aap_organization_name }}"
    source: scm
    source_project: "{{ aap_prefix }}"
    source_path: "inventory/localhost.yml"
    inventory: "{{ aap_prefix }}-cluster-fulfillment"
    overwrite: true
    overwrite_vars: true
    update_cache_timeout: 0
  - name: "{{ aap_prefix }}-config-as-code-is"
    organization: "{{ aap_organization_name }}"
    source: scm
    source_project: "{{ aap_prefix }}"
    source_path: "inventory/localhost.yml"
    inventory: "{{ aap_prefix }}-config-as-code"
    overwrite: true
    overwrite_vars: true
    update_cache_timeout: 0
  - name: "{{ aap_prefix }}-publish-templates-is"
    organization: "{{ aap_organization_name }}"
    source: scm
    source_project: "{{ aap_prefix }}"
    source_path: "inventory/localhost.yml"
    inventory: "{{ aap_prefix }}-publish-templates"
    overwrite: true
    overwrite_vars: true
    update_cache_timeout: 0
  - name: "{{ aap_prefix }}-compute-instance-operations-is"
    organization: "{{ aap_organization_name }}"
    source: scm
    source_project: "{{ aap_prefix }}"
    source_path: "inventory/localhost.yml"
    inventory: "{{ aap_prefix }}-compute-instance-operations"
    overwrite: true
    overwrite_vars: true
    update_cache_timeout: 0
  - name: "{{ aap_prefix }}-hostpool-operations-is"
    organization: "{{ aap_organization_name }}"
    source: scm
    source_project: "{{ aap_prefix }}"
    source_path: "inventory/localhost.yml"
    inventory: "{{ aap_prefix }}-hostpool-operations"
    overwrite: true
    overwrite_vars: true
    update_cache_timeout: 0

controller_schedules: # noqa: var-naming[no-role-prefix]
  # Sync project every 10min to get the latest updates from the git repository
  - name: "{{ aap_prefix }}-sync"
    description: "Periodic sync job for {{ aap_project_name }} project"
    organization: "{{ aap_organization_name }}"
    unified_job_template: "{{ aap_prefix }}"
    rrule: "DTSTART:20250331T144500Z RRULE:FREQ=MINUTELY;INTERVAL=10"
  # Run config-as-code template every hour to apply new changes, if any
  - name: "{{ aap_prefix }}-config-as-code"
    description: "Periodic run of config-as-code"
    organization: "{{ aap_organization_name }}"
    unified_job_template: "{{ aap_prefix }}-config-as-code"
    rrule: "DTSTART:20250331T144500Z RRULE:FREQ=HOURLY;INTERVAL=1"
  - name: "{{ aap_prefix }}-publish-templates"
    description: "Periodic run of publish-templates"
    organization: "{{ aap_organization_name }}"
    unified_job_template: "{{ aap_prefix }}-publish-templates"
    rrule: "DTSTART:20250513T111500Z RRULE:FREQ=MINUTELY;INTERVAL=30"

# Create custom execution environments
controller_execution_environments: # noqa: var-naming[no-role-prefix]
  - name: "{{ aap_prefix }}-ee"
    organization: "{{ aap_organization_name }}"
    image: "{{ aap_ee_image }}"
    pull: always

# Customize pod templates in order to inject the configuration and the
# credentials when the template are run, that way Kubernetes is the source
# of truth for the secrets, and we don't need to sync credentials into AAP
controller_instance_groups: # noqa: var-naming[no-role-prefix]
  # For cluster-fulfillment use cases, we want to allow KubeAPI access to the
  # cluster the pod works on, so we mount the credentials for the cloudkit
  # ServiceAccount. All other credentials (AWS, Openstack, ...) that would be
  # required by the playbooks are expected to be specified in the
  # (prefix)-cluster-fulfilment-ig secret.
  - name: "{{ aap_prefix }}-cluster-fulfillment-ig"
    is_container_group: true
    pod_spec_override: |
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          ansible_job: ''
      spec:
        serviceAccountName: cloudkit-sa
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: ansible_job
                        operator: Exists
                  topologyKey: kubernetes.io/hostname
        containers:
          - image: >-
              registry.redhat.io/ansible-automation-platform-25/ee-supported-rhel8@sha256:d8400a472e769d0f3d591dafaad318522009c583b08e881c23b6d57a27cc10ed
            name: worker
            args:
              - ansible-runner
              - worker
              - '--private-data-dir=/runner'
            volumeMounts:
              - name: kube-api-access
                mountPath: /var/run/secrets/kubernetes.io/serviceaccount
                readOnly: true
            env:
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: POD_UID
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.uid
            envFrom:
              - secretRef:
                  name: cluster-fulfillment-ig
        volumes:
        - name: kube-api-access
          projected:
            sources:
              - serviceAccountToken:
                  path: token
                  expirationSeconds: 3600
              - configMap:
                  name: kube-root-ca.crt
                  items:
                    - key: ca.crt
                      path: ca.crt
              - downwardAPI:
                  items:
                    - path: namespace
                      fieldRef:
                        apiVersion: v1
                        fieldPath: metadata.namespace
              - configMap:
                  name: openshift-service-ca.crt
                  items:
                    - key: service-ca.crt
                      path: service-ca.crt
            defaultMode: 420
  # For config-as-code job template, we expect the configuration and the
  # credentials to be passed in (prefix)-config-as-code-ig secret
  - name: "{{ aap_prefix }}-config-as-code-ig"
    is_container_group: true
    pod_spec_override: |
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          ansible_job: ''
      spec:
        serviceAccountName: default
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: ansible_job
                        operator: Exists
                  topologyKey: kubernetes.io/hostname
        containers:
          - image: >-
              registry.redhat.io/ansible-automation-platform-25/ee-supported-rhel8@sha256:d8400a472e769d0f3d591dafaad318522009c583b08e881c23b6d57a27cc10ed
            name: worker
            args:
              - ansible-runner
              - worker
              - '--private-data-dir=/runner'
            envFrom:
              - secretRef:
                  name: config-as-code-ig
                  optional: true
            env:
              - name: NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: AAP_PASSWORD
                valueFrom:
                  secretKeyRef:
                    name: innabox-aap-admin-password
                    key: password
              - name: LICENSE_MANIFEST_PATH
                value: /var/secrets/config-as-code/license.zip
            volumeMounts:
              - name: config-as-code-manifest-volume
                mountPath: /var/secrets/config-as-code
                readOnly: true
        volumes:
          - name: config-as-code-manifest-volume
            secret:
              secretName: config-as-code-manifest-ig
  - name: "{{ aap_prefix }}-publish-templates-ig"
    is_container_group: true
    pod_spec_override: |
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          ansible_job: ''
      spec:
        serviceAccountName: template-publisher
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: ansible_job
                        operator: Exists
                  topologyKey: kubernetes.io/hostname
        containers:
          - image: >-
              registry.redhat.io/ansible-automation-platform-25/ee-supported-rhel8@sha256:d8400a472e769d0f3d591dafaad318522009c583b08e881c23b6d57a27cc10ed
            name: worker
            args:
              - ansible-runner
              - worker
              - '--private-data-dir=/runner'
            volumeMounts:
              - name: kube-api-access
                mountPath: /var/run/secrets/kubernetes.io/serviceaccount
                readOnly: true
              - name: cas
                mountPath: /certs
            envFrom:
              - configMapRef:
                  name: publish-templates-ig
                  optional: true
            env:
              - name: CLOUDKIT_PUBLISH_TEMPLATES_NAMESPACE_DEFAULT
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: SSL_CERT_FILE
                value: /certs/bundle.pem
        volumes:
          - name: kube-api-access
            projected:
              sources:
                - serviceAccountToken:
                    path: token
                    expirationSeconds: 3600
                - configMap:
                    name: kube-root-ca.crt
                    items:
                      - key: ca.crt
                        path: ca.crt
                - downwardAPI:
                    items:
                      - path: namespace
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                - configMap:
                    name: openshift-service-ca.crt
                    items:
                      - key: service-ca.crt
                        path: service-ca.crt
              defaultMode: 420
          - name: cas
            configMap:
              name: ca-bundle
  - name: "{{ aap_prefix }}-create-hosted-cluster-post-install-ig"
    is_container_group: true

  - name: "{{ aap_prefix }}-compute-instance-operations-ig"
    is_container_group: true
    pod_spec_override: |
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          ansible_job: ''
      spec:
        serviceAccountName: cloudkit-sa
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: ansible_job
                        operator: Exists
                  topologyKey: kubernetes.io/hostname
        containers:
          - image: >-
              {{ aap_ee_image }}
            name: worker
            args:
              - ansible-runner
              - worker
              - '--private-data-dir=/runner'
            volumeMounts:
              - name: kube-api-access
                mountPath: /var/run/secrets/kubernetes.io/serviceaccount
                readOnly: true
            envFrom:
              - secretRef:
                  name: cluster-fulfillment-ig
            env:
              - name: CLOUDKIT_COMPUTE_INSTANCE_OPERATIONS_NAMESPACE_DEFAULT
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
        volumes:
          - name: kube-api-access
            projected:
              sources:
                - serviceAccountToken:
                    path: token
                    expirationSeconds: 3600
                - configMap:
                    name: kube-root-ca.crt
                    items:
                      - key: ca.crt
                        path: ca.crt
                - downwardAPI:
                    items:
                      - path: namespace
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                - configMap:
                    name: openshift-service-ca.crt
                    items:
                      - key: service-ca.crt
                        path: service-ca.crt
              defaultMode: 420

  - name: "{{ aap_prefix }}-hostpool-operations-ig"
    is_container_group: true
    pod_spec_override: |
      apiVersion: v1
      kind: Pod
      metadata:
        labels:
          ansible_job: ''
      spec:
        serviceAccountName: cloudkit-sa
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                podAffinityTerm:
                  labelSelector:
                    matchExpressions:
                      - key: ansible_job
                        operator: Exists
                  topologyKey: kubernetes.io/hostname
        containers:
          - image: >-
              {{ aap_ee_image }}
            name: worker
            args:
              - ansible-runner
              - worker
              - '--private-data-dir=/runner'
            volumeMounts:
              - name: kube-api-access
                mountPath: /var/run/secrets/kubernetes.io/serviceaccount
                readOnly: true
              - name: cas
                mountPath: /certs
            env:
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: POD_UID
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.uid
              - name: SSL_CERT_FILE
                value: /certs/bundle.pem
            envFrom:
              - secretRef:
                  name: cluster-fulfillment-ig
        volumes:
          - name: kube-api-access
            projected:
              sources:
                - serviceAccountToken:
                    path: token
                    expirationSeconds: 3600
                - configMap:
                    name: kube-root-ca.crt
                    items:
                      - key: ca.crt
                        path: ca.crt
                - downwardAPI:
                    items:
                      - path: namespace
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                - configMap:
                    name: openshift-service-ca.crt
                    items:
                      - key: service-ca.crt
                        path: service-ca.crt
              defaultMode: 420
          - name: cas
            configMap:
              name: ca-bundle
